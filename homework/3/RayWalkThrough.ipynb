{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray\n",
    "\n",
    "## References\n",
    "* Walkthrough of material from: https://github.com/ray-project/tutorial/blob/master/rllib_exercises/rllib_exercise02_ppo.ipynb\n",
    "\n",
    "## Pre install steps\n",
    "* Start a jupyter notebook on linux/mac. I will pip packages into a fresh conda environment. Preferred method:\n",
    "```conda create --name ray_ece python=3.7 pip jupyter```\n",
    "\n",
    "* Use docker with the same sort of environment.\n",
    "* **SOON**: jupyterhub environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Ray and RLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ray using ipynb/jupyter **magic** `!`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Be sure to install the latest version of RLlib and sundry requirements\n",
    "! pip install -U ray[rllib]\n",
    "! pip install requests pandas aiohttp psutil setproctitle grpcio tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# view dependencies\n",
    "! pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the basic pieces for ray/rllib. We will look at PPO applied to a gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ray\n",
    "* We explore a simple local configuration\n",
    "* Many configurations for distributed computation available: https://ray.readthedocs.io/en/latest/package-ref.html#ray.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-04 15:57:39,826\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-03-04 15:57:39,831\tINFO resource_spec.py:212 -- Starting Ray with 37.6 GiB memory available for workers and up to 18.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-03-04 15:57:40,311\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "2020-03-04 15:57:40,318\tWARNING services.py:1403 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.2',\n",
       " 'redis_address': '172.17.0.2:34143',\n",
       " 'object_store_address': '/tmp/ray/session_2020-03-04_15-57-39_824848_35/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-03-04_15-57-39_824848_35/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-03-04_15-57-39_824848_35'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start ray locally (there are lots of configurations)\n",
    "ray.init(num_cpus=4, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running RLlib PPO on cartpole\n",
    "\n",
    "### Config and patterns used in RLlib\n",
    "* RLlib uses a functional pattern where as much of configuration as possible is pushed to data (possibly data gathered at runtime).\n",
    "* Read more about this approach: https://bair.berkeley.edu/blog/2019/10/14/functional-rl/\n",
    "* Here we explore the base configuration some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': None, 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy() # just a dictionary that has been imported and copied\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-04 15:57:41,248\tINFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-03-04 15:57:41,269\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n",
      "2020-03-04 15:57:41,272\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/opt/conda/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\n",
      "2020-03-04 15:57:41,466\tWARNING worker.py:1058 -- The dashboard on node af27f73862c9 failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 920, in <module>\n",
      "    dashboard.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 368, in run\n",
      "    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/aiohttp/web.py\", line 433, in run_app\n",
      "    reuse_port=reuse_port))\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 579, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/aiohttp/web.py\", line 359, in _run_app\n",
      "    await site.start()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/aiohttp/web_runner.py\", line 104, in start\n",
      "    reuse_port=self._reuse_port)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1374, in create_server\n",
      "    % (sa, err.strerror.lower())) from None\n",
      "OSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n",
      "\n",
      "2020-03-04 15:57:46,374\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# change values at particular keys (note this could all come from yaml or json)\n",
    "config['num_workers'] = 1\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = PPOTrainer(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-57-58\n",
      "done: false\n",
      "episode_len_mean: 22.353932584269664\n",
      "episode_reward_max: 89.0\n",
      "episode_reward_mean: 22.353932584269664\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 178\n",
      "episodes_total: 178\n",
      "experiment_id: 854cae551b5843ef98a187d809a9731d\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 2344.363\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6640250086784363\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.030091295018792152\n",
      "      policy_loss: -0.039826083928346634\n",
      "      total_loss: 137.75889587402344\n",
      "      vf_explained_var: 0.034579798579216\n",
      "      vf_loss: 137.7926788330078\n",
      "  load_time_ms: 72.596\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 3968\n",
      "  sample_time_ms: 8583.601\n",
      "  update_time_ms: 522.156\n",
      "iterations_since_restore: 1\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 14.282352941176471\n",
      "  ram_util_percent: 18.98235294117647\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.08956678686544794\n",
      "  mean_inference_ms: 1.3134475947320239\n",
      "  mean_processing_ms: 0.2788261484128479\n",
      "time_since_restore: 11.583893060684204\n",
      "time_this_iter_s: 11.583893060684204\n",
      "time_total_s: 11.583893060684204\n",
      "timestamp: 1583337478\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-05\n",
      "done: false\n",
      "episode_len_mean: 38.50961538461539\n",
      "episode_reward_max: 129.0\n",
      "episode_reward_mean: 38.50961538461539\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 104\n",
      "episodes_total: 282\n",
      "experiment_id: 854cae551b5843ef98a187d809a9731d\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 2050.431\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6189860105514526\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.016670025885105133\n",
      "      policy_loss: -0.02543678507208824\n",
      "      total_loss: 253.98150634765625\n",
      "      vf_explained_var: 0.035378456115722656\n",
      "      vf_loss: 254.0018768310547\n",
      "  load_time_ms: 37.842\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 7936\n",
      "  sample_time_ms: 7273.062\n",
      "  update_time_ms: 262.91\n",
      "iterations_since_restore: 2\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 17.07272727272727\n",
      "  ram_util_percent: 19.0\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.08446555512500634\n",
      "  mean_inference_ms: 1.2384865108452325\n",
      "  mean_processing_ms: 0.2527804005788186\n",
      "time_since_restore: 19.315574169158936\n",
      "time_this_iter_s: 7.7316811084747314\n",
      "time_total_s: 19.315574169158936\n",
      "timestamp: 1583337485\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ray.rllib.agents.trainer.Trainer._setup.<locals>.<lambda>(env_config)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the builder pattern is everywhere ...\n",
    "agent.env_creator # environment is not stored, a function that creates an environment is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimeLimit<CartPoleEnv<CartPole-v0>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = agent.env_creator({}) # we can sometimes still get what we want ..\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\n",
      "Discrete(2)\n",
      "[-1.8682804e+00 -2.0490057e+38 -4.0107661e-01 -2.6536361e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute some observation, then ask the agent to compute an action\n",
    "obs = env.observation_space.sample()\n",
    "agent.compute_action(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE:\n",
    "Train the agent and try to get a reward of 200. If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger sgd_minibatch_size, a smaller num_sgd_iter, or a larger num_workers.\n",
    "\n",
    "This should take around 20 or 30 training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-04 15:58:06,020\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n",
      "/opt/conda/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\n",
      "2020-03-04 15:58:10,153\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# build out a new config and trainer\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0\n",
    "\n",
    "agent = PPOTrainer(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-16\n",
      "done: false\n",
      "episode_len_mean: 21.900552486187845\n",
      "episode_reward_max: 95.0\n",
      "episode_reward_mean: 21.900552486187845\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 181\n",
      "episodes_total: 181\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 2239.453\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6628535985946655\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.03046100027859211\n",
      "      policy_loss: -0.03643565624952316\n",
      "      total_loss: 174.53184509277344\n",
      "      vf_explained_var: 0.03705925494432449\n",
      "      vf_loss: 174.56216430664062\n",
      "  load_time_ms: 62.583\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 3968\n",
      "  sample_time_ms: 3262.039\n",
      "  update_time_ms: 631.169\n",
      "iterations_since_restore: 1\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.32\n",
      "  ram_util_percent: 19.52\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.0655536916566997\n",
      "  mean_inference_ms: 1.0038506177520596\n",
      "  mean_processing_ms: 0.213204636591164\n",
      "time_since_restore: 6.253625392913818\n",
      "time_this_iter_s: 6.253625392913818\n",
      "time_total_s: 6.253625392913818\n",
      "timestamp: 1583337496\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-20\n",
      "done: false\n",
      "episode_len_mean: 37.72549019607843\n",
      "episode_reward_max: 131.0\n",
      "episode_reward_mean: 37.72549019607843\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 102\n",
      "episodes_total: 283\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1905.11\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6186527609825134\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.015562096610665321\n",
      "      policy_loss: -0.027294734492897987\n",
      "      total_loss: 303.4728088378906\n",
      "      vf_explained_var: 0.03328545019030571\n",
      "      vf_loss: 303.49542236328125\n",
      "  load_time_ms: 32.667\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 7936\n",
      "  sample_time_ms: 2562.441\n",
      "  update_time_ms: 317.344\n",
      "iterations_since_restore: 2\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.339999999999996\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06769686733754658\n",
      "  mean_inference_ms: 1.020376768774308\n",
      "  mean_processing_ms: 0.21062829695547566\n",
      "time_since_restore: 9.698939085006714\n",
      "time_this_iter_s: 3.4453136920928955\n",
      "time_total_s: 9.698939085006714\n",
      "timestamp: 1583337500\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-23\n",
      "done: false\n",
      "episode_len_mean: 61.26\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 61.26\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 47\n",
      "episodes_total: 330\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1855.157\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5984804034233093\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.010341827757656574\n",
      "      policy_loss: -0.015770794823765755\n",
      "      total_loss: 547.0751342773438\n",
      "      vf_explained_var: 0.04093092307448387\n",
      "      vf_loss: 547.0877685546875\n",
      "  load_time_ms: 22.398\n",
      "  num_steps_sampled: 12000\n",
      "  num_steps_trained: 11904\n",
      "  sample_time_ms: 2271.912\n",
      "  update_time_ms: 212.493\n",
      "iterations_since_restore: 3\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.78\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.07107820583038833\n",
      "  mean_inference_ms: 1.060963977574426\n",
      "  mean_processing_ms: 0.21734474684685487\n",
      "time_since_restore: 13.155590057373047\n",
      "time_this_iter_s: 3.456650972366333\n",
      "time_total_s: 13.155590057373047\n",
      "timestamp: 1583337503\n",
      "timesteps_since_restore: 12000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 12000\n",
      "training_iteration: 3\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-27\n",
      "done: false\n",
      "episode_len_mean: 89.9\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 89.9\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 31\n",
      "episodes_total: 361\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1818.657\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5756151080131531\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006303214468061924\n",
      "      policy_loss: -0.010933791287243366\n",
      "      total_loss: 648.203369140625\n",
      "      vf_explained_var: 0.09783138334751129\n",
      "      vf_loss: 648.2123413085938\n",
      "  load_time_ms: 17.275\n",
      "  num_steps_sampled: 16000\n",
      "  num_steps_trained: 15872\n",
      "  sample_time_ms: 2195.06\n",
      "  update_time_ms: 160.381\n",
      "iterations_since_restore: 4\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.640000000000004\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06968707079659732\n",
      "  mean_inference_ms: 1.037013484220741\n",
      "  mean_processing_ms: 0.20932007891981527\n",
      "time_since_restore: 16.840134382247925\n",
      "time_this_iter_s: 3.684544324874878\n",
      "time_total_s: 16.840134382247925\n",
      "timestamp: 1583337507\n",
      "timesteps_since_restore: 16000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 16000\n",
      "training_iteration: 4\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-30\n",
      "done: false\n",
      "episode_len_mean: 118.51\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 118.51\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 385\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1826.725\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.571013867855072\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005186352413147688\n",
      "      policy_loss: -0.00494425930082798\n",
      "      total_loss: 574.6438598632812\n",
      "      vf_explained_var: 0.03178141266107559\n",
      "      vf_loss: 574.6472778320312\n",
      "  load_time_ms: 14.434\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 19840\n",
      "  sample_time_ms: 2115.471\n",
      "  update_time_ms: 128.991\n",
      "iterations_since_restore: 5\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.619999999999997\n",
      "  ram_util_percent: 19.580000000000002\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06910315346517432\n",
      "  mean_inference_ms: 1.0209188505255637\n",
      "  mean_processing_ms: 0.2035402373521059\n",
      "time_since_restore: 20.508267164230347\n",
      "time_this_iter_s: 3.668132781982422\n",
      "time_total_s: 20.508267164230347\n",
      "timestamp: 1583337510\n",
      "timesteps_since_restore: 20000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 20000\n",
      "training_iteration: 5\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-34\n",
      "done: false\n",
      "episode_len_mean: 139.91\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 139.91\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 406\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1786.288\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5411081910133362\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005344491917639971\n",
      "      policy_loss: -0.00763875525444746\n",
      "      total_loss: 689.2612915039062\n",
      "      vf_explained_var: 0.015218350104987621\n",
      "      vf_loss: 689.2672729492188\n",
      "  load_time_ms: 12.394\n",
      "  num_steps_sampled: 24000\n",
      "  num_steps_trained: 23808\n",
      "  sample_time_ms: 2049.806\n",
      "  update_time_ms: 108.145\n",
      "iterations_since_restore: 6\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.12\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.07001348812468425\n",
      "  mean_inference_ms: 1.0313223277956818\n",
      "  mean_processing_ms: 0.2038814460910342\n",
      "time_since_restore: 23.824785232543945\n",
      "time_this_iter_s: 3.3165180683135986\n",
      "time_total_s: 23.824785232543945\n",
      "timestamp: 1583337514\n",
      "timesteps_since_restore: 24000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 24000\n",
      "training_iteration: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-38\n",
      "done: false\n",
      "episode_len_mean: 163.14\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 163.14\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 427\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1817.669\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5416647791862488\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.002818094799295068\n",
      "      policy_loss: -0.0009219517232850194\n",
      "      total_loss: 509.164306640625\n",
      "      vf_explained_var: 0.04579988867044449\n",
      "      vf_loss: 509.1644592285156\n",
      "  load_time_ms: 11.098\n",
      "  num_steps_sampled: 28000\n",
      "  num_steps_trained: 27776\n",
      "  sample_time_ms: 2020.249\n",
      "  update_time_ms: 93.12\n",
      "iterations_since_restore: 7\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 22.619999999999997\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06949297490476163\n",
      "  mean_inference_ms: 1.0220584836657856\n",
      "  mean_processing_ms: 0.20021017874473074\n",
      "time_since_restore: 27.68531346321106\n",
      "time_this_iter_s: 3.8605282306671143\n",
      "time_total_s: 27.68531346321106\n",
      "timestamp: 1583337518\n",
      "timesteps_since_restore: 28000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 28000\n",
      "training_iteration: 7\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-41\n",
      "done: false\n",
      "episode_len_mean: 173.4\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 173.4\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 447\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1832.447\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.15000000596046448\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5501313805580139\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0057368106208741665\n",
      "      policy_loss: -0.0042630890384316444\n",
      "      total_loss: 517.2769165039062\n",
      "      vf_explained_var: 0.10048163682222366\n",
      "      vf_loss: 517.2803344726562\n",
      "  load_time_ms: 10.073\n",
      "  num_steps_sampled: 32000\n",
      "  num_steps_trained: 31744\n",
      "  sample_time_ms: 2005.122\n",
      "  update_time_ms: 82.185\n",
      "iterations_since_restore: 8\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 22.683333333333334\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06947666745576277\n",
      "  mean_inference_ms: 1.0213656667793671\n",
      "  mean_processing_ms: 0.19874269620265708\n",
      "time_since_restore: 31.534138202667236\n",
      "time_this_iter_s: 3.8488247394561768\n",
      "time_total_s: 31.534138202667236\n",
      "timestamp: 1583337521\n",
      "timesteps_since_restore: 32000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 32000\n",
      "training_iteration: 8\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-45\n",
      "done: false\n",
      "episode_len_mean: 186.38\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.38\n",
      "episode_reward_min: 37.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 469\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1834.051\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.15000000596046448\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5555005073547363\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0010471763089299202\n",
      "      policy_loss: 0.00047584142885170877\n",
      "      total_loss: 479.4190673828125\n",
      "      vf_explained_var: 0.19266864657402039\n",
      "      vf_loss: 479.41839599609375\n",
      "  load_time_ms: 9.322\n",
      "  num_steps_sampled: 36000\n",
      "  num_steps_trained: 35712\n",
      "  sample_time_ms: 1984.844\n",
      "  update_time_ms: 73.48\n",
      "iterations_since_restore: 9\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 22.86\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06951074487579705\n",
      "  mean_inference_ms: 1.0204203068292055\n",
      "  mean_processing_ms: 0.1973729086079001\n",
      "time_since_restore: 35.21842551231384\n",
      "time_this_iter_s: 3.6842873096466064\n",
      "time_total_s: 35.21842551231384\n",
      "timestamp: 1583337525\n",
      "timesteps_since_restore: 36000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 36000\n",
      "training_iteration: 9\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-49\n",
      "done: false\n",
      "episode_len_mean: 192.76\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.76\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 489\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1842.732\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5429763197898865\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.004755503032356501\n",
      "      policy_loss: -0.006064343731850386\n",
      "      total_loss: 402.8555908203125\n",
      "      vf_explained_var: 0.19323284924030304\n",
      "      vf_loss: 402.86126708984375\n",
      "  load_time_ms: 8.698\n",
      "  num_steps_sampled: 40000\n",
      "  num_steps_trained: 39680\n",
      "  sample_time_ms: 1967.904\n",
      "  update_time_ms: 66.554\n",
      "iterations_since_restore: 10\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 22.599999999999998\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06920417882191705\n",
      "  mean_inference_ms: 1.0166354220345641\n",
      "  mean_processing_ms: 0.19545624649779555\n",
      "time_since_restore: 38.96723961830139\n",
      "time_this_iter_s: 3.748814105987549\n",
      "time_total_s: 38.96723961830139\n",
      "timestamp: 1583337529\n",
      "timesteps_since_restore: 40000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 40000\n",
      "training_iteration: 10\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-52\n",
      "done: false\n",
      "episode_len_mean: 195.28\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.28\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 509\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1798.02\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5496981143951416\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006857750006020069\n",
      "      policy_loss: -0.001995249418541789\n",
      "      total_loss: 358.34002685546875\n",
      "      vf_explained_var: 0.2231774777173996\n",
      "      vf_loss: 358.341796875\n",
      "  load_time_ms: 2.71\n",
      "  num_steps_sampled: 44000\n",
      "  num_steps_trained: 43648\n",
      "  sample_time_ms: 1806.036\n",
      "  update_time_ms: 3.844\n",
      "iterations_since_restore: 11\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.374999999999996\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06902158513312791\n",
      "  mean_inference_ms: 1.0142693595010284\n",
      "  mean_processing_ms: 0.19424085837231472\n",
      "time_since_restore: 42.4151668548584\n",
      "time_this_iter_s: 3.447927236557007\n",
      "time_total_s: 42.4151668548584\n",
      "timestamp: 1583337532\n",
      "timesteps_since_restore: 44000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 44000\n",
      "training_iteration: 11\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-56\n",
      "done: false\n",
      "episode_len_mean: 196.6\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.6\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 529\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1815.277\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5265336036682129\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.004415085073560476\n",
      "      policy_loss: -0.0013574494514614344\n",
      "      total_loss: 342.15570068359375\n",
      "      vf_explained_var: 0.28830432891845703\n",
      "      vf_loss: 342.1569519042969\n",
      "  load_time_ms: 2.62\n",
      "  num_steps_sampled: 48000\n",
      "  num_steps_trained: 47616\n",
      "  sample_time_ms: 1794.317\n",
      "  update_time_ms: 4.27\n",
      "iterations_since_restore: 12\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.64\n",
      "  ram_util_percent: 19.54\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06892700131250282\n",
      "  mean_inference_ms: 1.0126427056608804\n",
      "  mean_processing_ms: 0.19343158076971798\n",
      "time_since_restore: 45.919344425201416\n",
      "time_this_iter_s: 3.5041775703430176\n",
      "time_total_s: 45.919344425201416\n",
      "timestamp: 1583337536\n",
      "timesteps_since_restore: 48000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 48000\n",
      "training_iteration: 12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-58-59\n",
      "done: false\n",
      "episode_len_mean: 197.93\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.93\n",
      "episode_reward_min: 128.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 549\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1820.087\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.01875000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5463908314704895\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.007513274904340506\n",
      "      policy_loss: -0.003791114082559943\n",
      "      total_loss: 371.29107666015625\n",
      "      vf_explained_var: 0.19435717165470123\n",
      "      vf_loss: 371.29473876953125\n",
      "  load_time_ms: 2.718\n",
      "  num_steps_sampled: 52000\n",
      "  num_steps_trained: 51584\n",
      "  sample_time_ms: 1791.978\n",
      "  update_time_ms: 4.344\n",
      "iterations_since_restore: 13\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.0\n",
      "  ram_util_percent: 19.52\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06881089641215844\n",
      "  mean_inference_ms: 1.0106500893585304\n",
      "  mean_processing_ms: 0.1927094887717927\n",
      "time_since_restore: 49.40386772155762\n",
      "time_this_iter_s: 3.484523296356201\n",
      "time_total_s: 49.40386772155762\n",
      "timestamp: 1583337539\n",
      "timesteps_since_restore: 52000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 52000\n",
      "training_iteration: 13\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-03\n",
      "done: false\n",
      "episode_len_mean: 197.74\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.74\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 569\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1836.044\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.01875000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5513816475868225\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0050466638058424\n",
      "      policy_loss: -0.006405837368220091\n",
      "      total_loss: 380.5085754394531\n",
      "      vf_explained_var: 0.20595157146453857\n",
      "      vf_loss: 380.514892578125\n",
      "  load_time_ms: 2.85\n",
      "  num_steps_sampled: 56000\n",
      "  num_steps_trained: 55552\n",
      "  sample_time_ms: 1773.35\n",
      "  update_time_ms: 4.372\n",
      "iterations_since_restore: 14\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.016666666666666\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06861867004784886\n",
      "  mean_inference_ms: 1.0076952755793172\n",
      "  mean_processing_ms: 0.19182463181036674\n",
      "time_since_restore: 53.06383943557739\n",
      "time_this_iter_s: 3.6599717140197754\n",
      "time_total_s: 53.06383943557739\n",
      "timestamp: 1583337543\n",
      "timesteps_since_restore: 56000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 56000\n",
      "training_iteration: 14\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-07\n",
      "done: false\n",
      "episode_len_mean: 198.39\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.39\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 589\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1816.352\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.01875000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5383890271186829\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006631254684180021\n",
      "      policy_loss: -0.0035323610063642263\n",
      "      total_loss: 391.1853332519531\n",
      "      vf_explained_var: 0.2276613861322403\n",
      "      vf_loss: 391.1887512207031\n",
      "  load_time_ms: 2.801\n",
      "  num_steps_sampled: 60000\n",
      "  num_steps_trained: 59520\n",
      "  sample_time_ms: 1790.973\n",
      "  update_time_ms: 4.522\n",
      "iterations_since_restore: 15\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.46\n",
      "  ram_util_percent: 19.5\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06854180991123571\n",
      "  mean_inference_ms: 1.0061230328513142\n",
      "  mean_processing_ms: 0.19128274465079337\n",
      "time_since_restore: 56.712597131729126\n",
      "time_this_iter_s: 3.6487576961517334\n",
      "time_total_s: 56.712597131729126\n",
      "timestamp: 1583337547\n",
      "timesteps_since_restore: 60000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 60000\n",
      "training_iteration: 15\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-10\n",
      "done: false\n",
      "episode_len_mean: 198.64\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.64\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 609\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1834.417\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.01875000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5576387047767639\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.004029487259685993\n",
      "      policy_loss: -0.0028195856139063835\n",
      "      total_loss: 261.6982727050781\n",
      "      vf_explained_var: 0.4862581491470337\n",
      "      vf_loss: 261.7010192871094\n",
      "  load_time_ms: 2.773\n",
      "  num_steps_sampled: 64000\n",
      "  num_steps_trained: 63488\n",
      "  sample_time_ms: 1783.257\n",
      "  update_time_ms: 4.597\n",
      "iterations_since_restore: 16\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.419999999999998\n",
      "  ram_util_percent: 19.660000000000004\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06847614738657365\n",
      "  mean_inference_ms: 1.0047693376519293\n",
      "  mean_processing_ms: 0.19086397680497702\n",
      "time_since_restore: 60.13322639465332\n",
      "time_this_iter_s: 3.4206292629241943\n",
      "time_total_s: 60.13322639465332\n",
      "timestamp: 1583337550\n",
      "timesteps_since_restore: 64000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 64000\n",
      "training_iteration: 16\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-14\n",
      "done: false\n",
      "episode_len_mean: 198.67\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.67\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 629\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1796.696\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5571776628494263\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.007845940068364143\n",
      "      policy_loss: -0.0069265528582036495\n",
      "      total_loss: 194.51754760742188\n",
      "      vf_explained_var: 0.6303754448890686\n",
      "      vf_loss: 194.52438354492188\n",
      "  load_time_ms: 2.756\n",
      "  num_steps_sampled: 68000\n",
      "  num_steps_trained: 67456\n",
      "  sample_time_ms: 1761.902\n",
      "  update_time_ms: 4.694\n",
      "iterations_since_restore: 17\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.779999999999994\n",
      "  ram_util_percent: 19.68\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06840198163938542\n",
      "  mean_inference_ms: 1.0030672736035593\n",
      "  mean_processing_ms: 0.1903405958728164\n",
      "time_since_restore: 63.402732372283936\n",
      "time_this_iter_s: 3.2695059776306152\n",
      "time_total_s: 63.402732372283936\n",
      "timestamp: 1583337554\n",
      "timesteps_since_restore: 68000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 68000\n",
      "training_iteration: 17\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-17\n",
      "done: false\n",
      "episode_len_mean: 198.67\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.67\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 649\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1799.081\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5533959269523621\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.012556611560285091\n",
      "      policy_loss: -0.003748205490410328\n",
      "      total_loss: 305.35162353515625\n",
      "      vf_explained_var: 0.48504433035850525\n",
      "      vf_loss: 305.355224609375\n",
      "  load_time_ms: 2.811\n",
      "  num_steps_sampled: 72000\n",
      "  num_steps_trained: 71424\n",
      "  sample_time_ms: 1753.309\n",
      "  update_time_ms: 4.449\n",
      "iterations_since_restore: 18\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.02\n",
      "  ram_util_percent: 19.7\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06835478534445509\n",
      "  mean_inference_ms: 1.0017616313905997\n",
      "  mean_processing_ms: 0.18990599535021338\n",
      "time_since_restore: 67.18859314918518\n",
      "time_this_iter_s: 3.785860776901245\n",
      "time_total_s: 67.18859314918518\n",
      "timestamp: 1583337557\n",
      "timesteps_since_restore: 72000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 72000\n",
      "training_iteration: 18\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-21\n",
      "done: false\n",
      "episode_len_mean: 199.15\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.15\n",
      "episode_reward_min: 180.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 669\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1798.823\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5689409971237183\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006725978571921587\n",
      "      policy_loss: -0.0030845978762954473\n",
      "      total_loss: 126.54732513427734\n",
      "      vf_explained_var: 0.7361378073692322\n",
      "      vf_loss: 126.55033874511719\n",
      "  load_time_ms: 2.689\n",
      "  num_steps_sampled: 76000\n",
      "  num_steps_trained: 75392\n",
      "  sample_time_ms: 1754.205\n",
      "  update_time_ms: 4.477\n",
      "iterations_since_restore: 19\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.459999999999997\n",
      "  ram_util_percent: 19.7\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06827287174148462\n",
      "  mean_inference_ms: 0.9997490978343936\n",
      "  mean_processing_ms: 0.18946581345627173\n",
      "time_since_restore: 70.87597274780273\n",
      "time_this_iter_s: 3.6873795986175537\n",
      "time_total_s: 70.87597274780273\n",
      "timestamp: 1583337561\n",
      "timesteps_since_restore: 76000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 76000\n",
      "training_iteration: 19\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-04_15-59-24\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 180.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 689\n",
      "experiment_id: 981f8facd69f43fc9a65b9028233dadd\n",
      "hostname: af27f73862c9\n",
      "info:\n",
      "  grad_time_ms: 1757.596\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5606156587600708\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005092380102723837\n",
      "      policy_loss: -0.0026435733307152987\n",
      "      total_loss: 153.61245727539062\n",
      "      vf_explained_var: 0.7301936745643616\n",
      "      vf_loss: 153.61505126953125\n",
      "  load_time_ms: 2.54\n",
      "  num_steps_sampled: 80000\n",
      "  num_steps_trained: 79360\n",
      "  sample_time_ms: 1746.159\n",
      "  update_time_ms: 4.474\n",
      "iterations_since_restore: 20\n",
      "node_ip: 172.17.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.72\n",
      "  ram_util_percent: 19.759999999999998\n",
      "pid: 35\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.06814272549421548\n",
      "  mean_inference_ms: 0.9969525383955066\n",
      "  mean_processing_ms: 0.1888524167774361\n",
      "time_since_restore: 74.12998032569885\n",
      "time_this_iter_s: 3.254007577896118\n",
      "time_total_s: 74.12998032569885\n",
      "timestamp: 1583337564\n",
      "timesteps_since_restore: 80000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 80000\n",
      "training_iteration: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train for a while\n",
    "for i in range(20):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ray_results/PPO_CartPole-v0_2020-03-04_15-58-06e1rblun3/checkpoint_20/checkpoint-20\n"
     ]
    }
   ],
   "source": [
    "## Save the agent off (this may become sticky depending which agent you've used)\n",
    "checkpoint_path = agent.save()\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-04 16:02:11,138\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n",
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/opt/conda/lib/python3.7/site-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\n",
      "2020-03-04 16:02:14,936\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-03-04 16:02:15,001\tWARNING trainable.py:210 -- Getting current IP.\n",
      "2020-03-04 16:02:15,002\tINFO trainable.py:416 -- Restored on 172.17.0.2 from checkpoint: /root/ray_results/PPO_CartPole-v0_2020-03-04_15-58-06e1rblun3/checkpoint_20/checkpoint-20\n",
      "2020-03-04 16:02:15,002\tINFO trainable.py:423 -- Current state after restoring: {'_iteration': 20, '_timesteps_total': 80000, '_time_total': 74.12998032569885, '_episodes_total': 689}\n"
     ]
    }
   ],
   "source": [
    "trained_config = config.copy() # copy training config (this is also located in ~/ray_results)\n",
    "test_agent = PPOTrainer(trained_config, 'CartPole-v0')\n",
    "test_agent.restore(checkpoint_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE:\n",
    "Verify that the reward received roughly matches up with the reward printed in the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "# same a single trajectory\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow ups:\n",
    "1. Using the `test_agent` what is the distribution of cummulative reward?\n",
    "1. Instead of a well trained agent, what does a poorly trained agent reward distribution look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring tune\n",
    "https://ray.readthedocs.io/en/latest/tune-usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Get logging from previous ppo training into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib and magic\n",
    "# ! pip install matplotlib\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import Analysis\n",
    "# change paths appropriately\n",
    "analysis = Analysis(\"/root/ray_results/PPO_CartPole-v0_2020-03-04_15-58-06e1rblun3\")\n",
    "\n",
    "# analysis = Analysis(\"/root/ray_results/PPO_CartPole-v0_2020-02-19_06-16-28270n8w37\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe() # last trial from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = analysis.trial_dataframes['/root/ray_results/PPO_CartPole-v0_2020-03-04_15-58-06e1rblun3']\n",
    "# df_trials = analysis.trial_dataframes['/home/jhineman/ray_results/PPO_CartPole-v0_2020-02-19_06-16-28270n8w37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f358fb33150>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials['episode_reward_mean'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Look at same with tensorboard. In a console, start tensorboard with: `tensorboard --logdir=~/ray_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.27.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (3.11.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (45.2.0.post20200210)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.15.0 at http://d9c1395b1459:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=~/ray_results --port=9999 # Kernel -> interupt to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details on tune\n",
    "* https://github.com/ray-project/ray/tree/master/rllib/tuned_examples list essentially yaml that can be used with the command line interface for tune\n",
    "* we will use tune to run of the a3c examples (this is a cpu only regression test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (5.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pyyaml # install package to read yamls, import with yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'# This gets to ~19-20 reward in ~30 minutes / 4m steps on a m4.10xl instance\\n# TODO(rliaw): this has regressed in performance\\npong-a3c:\\n    env: PongDeterministic-v4\\n    run: A3C\\n    config:\\n        num_workers: 16\\n        sample_batch_size: 20\\n        use_pytorch: false\\n        vf_loss_coeff: 0.5\\n        entropy_coeff: 0.01\\n        gamma: 0.99\\n        grad_clip: 40.0\\n        lambda: 1.0\\n        lr: 0.0001\\n        observation_filter: NoFilter\\n        preprocessor_pref: rllib\\n        model:\\n            use_lstm: true\\n            conv_activation: elu\\n            dim: 42\\n            grayscale: true\\n            zero_mean: false\\n            # Reduced channel depth and kernel size from default\\n            conv_filters: [\\n                [32, [3, 3], 2],\\n                [32, [3, 3], 2],\\n                [32, [3, 3], 2],\\n                [32, [3, 3], 2],\\n            ]\\n'\n"
     ]
    }
   ],
   "source": [
    "# grab an a3c example from github\n",
    "link = \"https://raw.githubusercontent.com/ray-project/ray/master/rllib/tuned_examples/pong-a3c.yaml\"\n",
    "f = urllib.request.urlopen(link)\n",
    "yaml_example = f.read()\n",
    "print(yaml_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pong-a3c': {'env': 'PongDeterministic-v4', 'run': 'A3C', 'config': {'num_workers': 16, 'sample_batch_size': 20, 'use_pytorch': False, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'gamma': 0.99, 'grad_clip': 40.0, 'lambda': 1.0, 'lr': 0.0001, 'observation_filter': 'NoFilter', 'preprocessor_pref': 'rllib', 'model': {'use_lstm': True, 'conv_activation': 'elu', 'dim': 42, 'grayscale': True, 'zero_mean': False, 'conv_filters': [[32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2]]}}}}\n"
     ]
    }
   ],
   "source": [
    "tune_config_example = yaml.safe_load(yaml_example)\n",
    "print(tune_config_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pong-a3c': {'env': 'PongDeterministic-v4', 'run': 'A3C', 'config': {'num_workers': 2, 'sample_batch_size': 20, 'use_pytorch': False, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'gamma': 0.99, 'grad_clip': 40.0, 'lambda': 1.0, 'lr': 0.0001, 'observation_filter': 'NoFilter', 'preprocessor_pref': 'rllib', 'model': {'use_lstm': True, 'conv_activation': 'elu', 'dim': 42, 'grayscale': True, 'zero_mean': False, 'conv_filters': [[32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2]]}}, 'stop': {'training_iteration': 10}}}\n"
     ]
    }
   ],
   "source": [
    "tune_config_example[\"pong-a3c\"][\"config\"][\"num_workers\"]=2\n",
    "tune_config_example[\"pong-a3c\"][\"stop\"] = {\"training_iteration\": 10}\n",
    "print(tune_config_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-04 16:02:57,031\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 820.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.504\n",
      "    dispatch_time_ms: 4.796\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 9.672812461853027\n",
      "      model: {}\n",
      "      policy_entropy: 35.81401443481445\n",
      "      policy_loss: 6.255337238311768\n",
      "      var_gnorm: 25.885271072387695\n",
      "      vf_explained_var: -0.2074357271194458\n",
      "      vf_loss: 0.33402764797210693\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    wait_time_ms: 30.377\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.76666666666667\n",
      "    ram_util_percent: 23.686666666666667\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3972177579709064\n",
      "    mean_inference_ms: 2.4810319744659304\n",
      "    mean_processing_ms: 0.5341527063095152\n",
      "  time_since_restore: 9.905626773834229\n",
      "  time_this_iter_s: 9.905626773834229\n",
      "  time_total_s: 9.905626773834229\n",
      "  timestamp: 1583337792\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 2000\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 1\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         9.90563</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">     1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-20\n",
      "  done: false\n",
      "  episode_len_mean: 904.4\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.4\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 5\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.574\n",
      "    dispatch_time_ms: 4.987\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 9.978023529052734\n",
      "      model: {}\n",
      "      policy_entropy: 35.75037384033203\n",
      "      policy_loss: 6.5493950843811035\n",
      "      var_gnorm: 25.895015716552734\n",
      "      vf_explained_var: -0.17675864696502686\n",
      "      vf_loss: 0.36715227365493774\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 6000\n",
      "    wait_time_ms: 31.196\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.309999999999995\n",
      "    ram_util_percent: 24.0\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3063195481252243\n",
      "    mean_inference_ms: 2.1292879859749716\n",
      "    mean_processing_ms: 0.510600535727982\n",
      "  time_since_restore: 17.05147385597229\n",
      "  time_this_iter_s: 7.1458470821380615\n",
      "  time_total_s: 17.05147385597229\n",
      "  timestamp: 1583337800\n",
      "  timesteps_since_restore: 6000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 2\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">   -20.4</td><td style=\"text-align: right;\">         17.0515</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">     2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-27\n",
      "  done: false\n",
      "  episode_len_mean: 931.9\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.3\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.573\n",
      "    dispatch_time_ms: 4.82\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 13.305801391601562\n",
      "      model: {}\n",
      "      policy_entropy: 35.7344970703125\n",
      "      policy_loss: 6.718070983886719\n",
      "      var_gnorm: 25.905691146850586\n",
      "      vf_explained_var: 0.15502434968948364\n",
      "      vf_loss: 0.5448382496833801\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    wait_time_ms: 29.493\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.879999999999995\n",
      "    ram_util_percent: 24.0\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2855086461069736\n",
      "    mean_inference_ms: 2.0429388630893635\n",
      "    mean_processing_ms: 0.5061402441826921\n",
      "  time_since_restore: 24.18766474723816\n",
      "  time_this_iter_s: 7.136190891265869\n",
      "  time_total_s: 24.18766474723816\n",
      "  timestamp: 1583337807\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 3\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">   -20.3</td><td style=\"text-align: right;\">         24.1877</td><td style=\"text-align: right;\">10000</td><td style=\"text-align: right;\">     3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-34\n",
      "  done: false\n",
      "  episode_len_mean: 913.2142857142857\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.428571428571427\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 14\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 2.431\n",
      "    dispatch_time_ms: 8.692\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 5.603128433227539\n",
      "      model: {}\n",
      "      policy_entropy: 35.785133361816406\n",
      "      policy_loss: -3.230623722076416\n",
      "      var_gnorm: 25.91425895690918\n",
      "      vf_explained_var: 0.0626024603843689\n",
      "      vf_loss: 1.5249757766723633\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 14000\n",
      "    wait_time_ms: 30.828\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.027272727272727\n",
      "    ram_util_percent: 24.0\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2791277866189419\n",
      "    mean_inference_ms: 2.009964726469381\n",
      "    mean_processing_ms: 0.5046617564606874\n",
      "  time_since_restore: 31.406708002090454\n",
      "  time_this_iter_s: 7.219043254852295\n",
      "  time_total_s: 31.406708002090454\n",
      "  timestamp: 1583337814\n",
      "  timesteps_since_restore: 14000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 4\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">-20.4286</td><td style=\"text-align: right;\">         31.4067</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">     4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-41\n",
      "  done: false\n",
      "  episode_len_mean: 913.9473684210526\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.42105263157895\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 19\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.604\n",
      "    dispatch_time_ms: 4.972\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_entropy: 35.724822998046875\n",
      "      policy_loss: 40.379737854003906\n",
      "      var_gnorm: 25.932632446289062\n",
      "      vf_explained_var: 0.03856581449508667\n",
      "      vf_loss: 12.452535629272461\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 18000\n",
      "    wait_time_ms: 30.181\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.439999999999998\n",
      "    ram_util_percent: 24.009999999999998\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2748976637298848\n",
      "    mean_inference_ms: 1.9840521420558512\n",
      "    mean_processing_ms: 0.5043244295188517\n",
      "  time_since_restore: 38.6375617980957\n",
      "  time_this_iter_s: 7.230853796005249\n",
      "  time_total_s: 38.6375617980957\n",
      "  timestamp: 1583337821\n",
      "  timesteps_since_restore: 18000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 5\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">-20.4211</td><td style=\"text-align: right;\">         38.6376</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">     5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 916.5652173913044\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.434782608695652\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 23\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.553\n",
      "    dispatch_time_ms: 4.996\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 7.161802291870117\n",
      "      model: {}\n",
      "      policy_entropy: 35.80634689331055\n",
      "      policy_loss: 3.2941999435424805\n",
      "      var_gnorm: 25.944604873657227\n",
      "      vf_explained_var: 0.0029311776161193848\n",
      "      vf_loss: 0.7741392254829407\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 22000\n",
      "    wait_time_ms: 29.542\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.74\n",
      "    ram_util_percent: 24.07\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2724637117991544\n",
      "    mean_inference_ms: 1.9690753440910505\n",
      "    mean_processing_ms: 0.5038514822769072\n",
      "  time_since_restore: 45.830528259277344\n",
      "  time_this_iter_s: 7.192966461181641\n",
      "  time_total_s: 45.830528259277344\n",
      "  timestamp: 1583337829\n",
      "  timesteps_since_restore: 22000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 6\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">-20.4348</td><td style=\"text-align: right;\">         45.8305</td><td style=\"text-align: right;\">22000</td><td style=\"text-align: right;\">     6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-03-56\n",
      "  done: false\n",
      "  episode_len_mean: 917.8888888888889\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.40740740740741\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 27\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.681\n",
      "    dispatch_time_ms: 5.249\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 8.96703052520752\n",
      "      model: {}\n",
      "      policy_entropy: 35.80378341674805\n",
      "      policy_loss: 6.355423927307129\n",
      "      var_gnorm: 25.962169647216797\n",
      "      vf_explained_var: 0.05139070749282837\n",
      "      vf_loss: 0.4432685673236847\n",
      "    num_steps_sampled: 26000\n",
      "    num_steps_trained: 26000\n",
      "    wait_time_ms: 30.114\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.820000000000004\n",
      "    ram_util_percent: 24.1\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2703271418313373\n",
      "    mean_inference_ms: 1.9567594982931582\n",
      "    mean_processing_ms: 0.5034663936588935\n",
      "  time_since_restore: 52.94291639328003\n",
      "  time_this_iter_s: 7.1123881340026855\n",
      "  time_total_s: 52.94291639328003\n",
      "  timestamp: 1583337836\n",
      "  timesteps_since_restore: 26000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 26000\n",
      "  training_iteration: 7\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">-20.4074</td><td style=\"text-align: right;\">         52.9429</td><td style=\"text-align: right;\">26000</td><td style=\"text-align: right;\">     7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-04-03\n",
      "  done: false\n",
      "  episode_len_mean: 928.8709677419355\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -20.29032258064516\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 31\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.61\n",
      "    dispatch_time_ms: 4.942\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 11.990363121032715\n",
      "      model: {}\n",
      "      policy_entropy: 35.743560791015625\n",
      "      policy_loss: 7.616125106811523\n",
      "      var_gnorm: 25.967660903930664\n",
      "      vf_explained_var: 0.082927405834198\n",
      "      vf_loss: 0.7093896865844727\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    wait_time_ms: 30.793\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.09090909090909\n",
      "    ram_util_percent: 24.1\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.26869411005676\n",
      "    mean_inference_ms: 1.9467327208419518\n",
      "    mean_processing_ms: 0.5031822835393541\n",
      "  time_since_restore: 60.10120224952698\n",
      "  time_this_iter_s: 7.158285856246948\n",
      "  time_total_s: 60.10120224952698\n",
      "  timestamp: 1583337843\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 8\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">-20.2903</td><td style=\"text-align: right;\">         60.1012</td><td style=\"text-align: right;\">30000</td><td style=\"text-align: right;\">     8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-04-10\n",
      "  done: false\n",
      "  episode_len_mean: 925.9428571428572\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -20.34285714285714\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 35\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.807\n",
      "    dispatch_time_ms: 6.075\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 9.824254035949707\n",
      "      model: {}\n",
      "      policy_entropy: 35.70308303833008\n",
      "      policy_loss: 7.222458362579346\n",
      "      var_gnorm: 25.987089157104492\n",
      "      vf_explained_var: 0.004716336727142334\n",
      "      vf_loss: 0.5531505346298218\n",
      "    num_steps_sampled: 34000\n",
      "    num_steps_trained: 34000\n",
      "    wait_time_ms: 29.503\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.77\n",
      "    ram_util_percent: 24.1\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2672064841339994\n",
      "    mean_inference_ms: 1.9383512802540281\n",
      "    mean_processing_ms: 0.5029131206836389\n",
      "  time_since_restore: 67.2305908203125\n",
      "  time_this_iter_s: 7.1293885707855225\n",
      "  time_total_s: 67.2305908203125\n",
      "  timestamp: 1583337850\n",
      "  timesteps_since_restore: 34000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 34000\n",
      "  training_iteration: 9\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-04 16:04:11,611\tWARNING util.py:132 -- The `process_trial` operation took 1.1385910511016846 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>RUNNING </td><td>172.17.0.2:353</td><td style=\"text-align: right;\">-20.3429</td><td style=\"text-align: right;\">         67.2306</td><td style=\"text-align: right;\">34000</td><td style=\"text-align: right;\">     9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_9d17eff8:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-04_16-04-18\n",
      "  done: true\n",
      "  episode_len_mean: 927.475\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -20.35\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 40\n",
      "  experiment_id: a4dcb02ee01c46039006edff7a59ac67\n",
      "  experiment_tag: '0'\n",
      "  hostname: af27f73862c9\n",
      "  info:\n",
      "    apply_time_ms: 1.552\n",
      "    dispatch_time_ms: 5.38\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 8.698119163513184\n",
      "      model: {}\n",
      "      policy_entropy: 35.717926025390625\n",
      "      policy_loss: 7.213077545166016\n",
      "      var_gnorm: 26.0128173828125\n",
      "      vf_explained_var: -0.0043523311614990234\n",
      "      vf_loss: 0.5089849829673767\n",
      "    num_steps_sampled: 38000\n",
      "    num_steps_trained: 38000\n",
      "    wait_time_ms: 29.287\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.516666666666666\n",
      "    ram_util_percent: 24.100000000000005\n",
      "  pid: 353\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.2660207942285415\n",
      "    mean_inference_ms: 1.9306879613689465\n",
      "    mean_processing_ms: 0.5028201301728503\n",
      "  time_since_restore: 74.30908226966858\n",
      "  time_this_iter_s: 7.078491449356079\n",
      "  time_total_s: 74.30908226966858\n",
      "  timestamp: 1583337858\n",
      "  timesteps_since_restore: 38000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 38000\n",
      "  training_iteration: 10\n",
      "  trial_id: 9d17eff8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">  -20.35</td><td style=\"text-align: right;\">         74.3091</td><td style=\"text-align: right;\">38000</td><td style=\"text-align: right;\">    10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/62.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/2 GPUs, 0.0/37.6 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /root/ray_results/pong-a3c<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_9d17eff8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">  -20.35</td><td style=\"text-align: right;\">         74.3091</td><td style=\"text-align: right;\">38000</td><td style=\"text-align: right;\">    10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[A3C_PongDeterministic-v4_9d17eff8]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.tune.run_experiments(tune_config_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting status and stopping ray\n",
    "* https://ray.readthedocs.io/en/latest/package-ref.html#ray-package-reference\n",
    "* https://ray.readthedocs.io/en/latest/package-ref.html#ray.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': 'fe79205044135b4e863f4ea5dec08835a6a281c9',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '172.17.0.2',\n",
       "  'NodeManagerHostname': 'af27f73862c9',\n",
       "  'NodeManagerPort': 60878,\n",
       "  'ObjectManagerPort': 38113,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2020-03-04_15-57-39_824848_35/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2020-03-04_15-57-39_824848_35/sockets/raylet',\n",
       "  'Resources': {'node:172.17.0.2': 1.0,\n",
       "   'CPU': 4.0,\n",
       "   'memory': 770.0,\n",
       "   'GPU': 2.0,\n",
       "   'object_store_memory': 263.0},\n",
       "  'alive': True}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node:172.17.0.2': 1.0,\n",
       " 'CPU': 4.0,\n",
       " 'memory': 770.0,\n",
       " 'GPU': 2.0,\n",
       " 'object_store_memory': 263.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
