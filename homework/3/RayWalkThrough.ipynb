{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray\n",
    "\n",
    "## References\n",
    "* Walkthrough of material from: https://github.com/ray-project/tutorial/blob/master/rllib_exercises/rllib_exercise02_ppo.ipynb\n",
    "\n",
    "## Pre install steps\n",
    "* Start a jupyter notebook on linux/mac. I will pip packages into a fresh conda environment. Preferred method:\n",
    "```conda create --name ray_ece python=3.7 pip jupyter```\n",
    "\n",
    "* Use docker with the same sort of environment.\n",
    "* **SOON**: jupyterhub environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Ray and RLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ray using ipynb/jupyter **magic** `!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: ray[rllib] in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: funcsigs in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pytest in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (5.3.5)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: redis>=3.3.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (3.11.3)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (20.1)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy; extra == \"rllib\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: lz4; extra == \"rllib\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: tabulate; extra == \"rllib\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (0.8.6)\n",
      "Requirement already satisfied, skipping upgrade: gym[atari]; extra == \"rllib\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python-headless; extra == \"rllib\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from ray[rllib]) (4.2.0.32)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pytest->ray[rllib]) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pytest->ray[rllib]) (8.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pytest->ray[rllib]) (0.13.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pytest->ray[rllib]) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pytest->ray[rllib]) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pytest->ray[rllib]) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from protobuf>=3.8.0->ray[rllib]) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from packaging->ray[rllib]) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from jsonschema->ray[rllib]) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow; extra == \"atari\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python; extra == \"atari\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.2.0.32)\n",
      "Requirement already satisfied, skipping upgrade: atari-py~=0.2.0; extra == \"atari\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (0.2.6)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->ray[rllib]) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: future in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.18.2)\n",
      "Requirement already satisfied: requests in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: pandas in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: aiohttp in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (3.6.2)\n",
      "Requirement already satisfied: psutil in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (5.7.0)\n",
      "Requirement already satisfied: setproctitle in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (1.1.10)\n",
      "Requirement already satisfied: grpcio in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (1.27.2)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from aiohttp) (19.3.0)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from aiohttp) (4.7.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from aiohttp) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from aiohttp) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from grpcio) (1.14.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Processing /home/jhineman/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp37-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
      "Processing /home/jhineman/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833/opt_einsum-3.1.0-cp37-none-any.whl\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Using cached Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.1.8-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Processing /home/jhineman/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp37-none-any.whl\n",
      "Processing /home/jhineman/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e/absl_py-0.9.0-py3-none-any.whl\n",
      "Processing /home/jhineman/.cache/pip/wheels/e5/78/69/f40ab7cae531c8f07003a9d1b4b81ebec14cda95519c57e7dd/wrapt-1.12.0-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting h5py\n",
      "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.2.0.post20200210)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.11.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Installing collected packages: tensorflow-estimator, astor, h5py, keras-applications, gast, oauthlib, requests-oauthlib, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, google-auth-oauthlib, werkzeug, absl-py, markdown, tensorboard, opt-einsum, keras-preprocessing, google-pasta, termcolor, wrapt, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.2 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.1.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 werkzeug-1.0.0 wrapt-1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Be sure to install the latest version of RLlib and sundry requirements\n",
    "! pip install -U ray[rllib]\n",
    "! pip install requests pandas aiohttp psutil setproctitle grpcio tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow             2.1.0              \r\n",
      "tensorflow-estimator   2.1.0              \r\n"
     ]
    }
   ],
   "source": [
    "# view dependencies\n",
    "! pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the basic pieces for ray/rllib. We will look at PPO applied to a gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ray\n",
    "* We explore a simple local configuration\n",
    "* Many configurations for distributed computation available: https://ray.readthedocs.io/en/latest/package-ref.html#ray.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 07:34:57,991\tERROR worker.py:688 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "# Start ray locally (there are lots of configurations)\n",
    "ray.init(num_cpus=4, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running RLlib PPO on cartpole\n",
    "\n",
    "### Config and patterns used in RLlib\n",
    "* RLlib uses a functional pattern where as much of configuration as possible is pushed to data (possibly data gathered at runtime).\n",
    "* Read more about this approach: https://bair.berkeley.edu/blog/2019/10/14/functional-rl/\n",
    "* Here we explore the base configuration some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 2,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'sample_batch_size': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'fcnet_hiddens': [256, 256],\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action_reward': False,\n",
       "  'state_shape': None,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_preprocessor': None,\n",
       "  'custom_model': None,\n",
       "  'custom_action_dist': None,\n",
       "  'custom_options': {}},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': {'on_episode_start': None,\n",
       "  'on_episode_step': None,\n",
       "  'on_episode_end': None,\n",
       "  'on_sample_end': None,\n",
       "  'on_train_result': None,\n",
       "  'on_postprocess_traj': None},\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'eager': False,\n",
       " 'eager_tracing': False,\n",
       " 'no_eager_on_workers': False,\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'evaluation_config': {},\n",
       " 'sample_async': False,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None},\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 30,\n",
       " 'lr_schedule': None,\n",
       " 'vf_share_layers': False,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy() # just a dictionary that has been imported and copied\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 05:47:46,523\tINFO trainer.py:370 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-02-19 05:47:46,531\tINFO trainer.py:517 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-02-19 05:47:49,027\tWARNING util.py:41 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# change values at particular keys (note this could all come from yaml or json)\n",
    "config['num_workers'] = 1\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = PPOTrainer(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-19_05-49-46\n",
      "done: false\n",
      "episode_len_mean: 21.43548387096774\n",
      "episode_reward_max: 76.0\n",
      "episode_reward_mean: 21.43548387096774\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 186\n",
      "episodes_total: 186\n",
      "experiment_id: c5db5e6c6f5f4e5a9577433130e8cd52\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1444.419\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6621034145355225\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.03152647987008095\n",
      "      policy_loss: -0.042134784162044525\n",
      "      total_loss: 148.3585968017578\n",
      "      vf_explained_var: 0.038961268961429596\n",
      "      vf_loss: 148.39442443847656\n",
      "  load_time_ms: 48.515\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 3968\n",
      "  sample_time_ms: 2788.601\n",
      "  update_time_ms: 403.083\n",
      "iterations_since_restore: 1\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 9.753892215568863\n",
      "  ram_util_percent: 53.06407185628743\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.04481625717838117\n",
      "  mean_inference_ms: 0.514977814346157\n",
      "  mean_processing_ms: 0.12035323393043953\n",
      "time_since_restore: 4.7226622104644775\n",
      "time_this_iter_s: 4.7226622104644775\n",
      "time_total_s: 4.7226622104644775\n",
      "timestamp: 1582109386\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_05-49-49\n",
      "done: false\n",
      "episode_len_mean: 38.50961538461539\n",
      "episode_reward_max: 129.0\n",
      "episode_reward_mean: 38.50961538461539\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 104\n",
      "episodes_total: 290\n",
      "experiment_id: c5db5e6c6f5f4e5a9577433130e8cd52\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1308.657\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6160285472869873\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.017372993752360344\n",
      "      policy_loss: -0.025630231946706772\n",
      "      total_loss: 225.67129516601562\n",
      "      vf_explained_var: 0.04346183314919472\n",
      "      vf_loss: 225.6917266845703\n",
      "  load_time_ms: 24.865\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 7936\n",
      "  sample_time_ms: 2715.174\n",
      "  update_time_ms: 202.632\n",
      "iterations_since_restore: 2\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.166666666666668\n",
      "  ram_util_percent: 53.0\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.04512637037885829\n",
      "  mean_inference_ms: 0.5051797664905991\n",
      "  mean_processing_ms: 0.11499213242647038\n",
      "time_since_restore: 8.54508376121521\n",
      "time_this_iter_s: 3.8224215507507324\n",
      "time_total_s: 8.54508376121521\n",
      "timestamp: 1582109389\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ray.rllib.agents.trainer.Trainer._setup.<locals>.<lambda>(env_config)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the builder pattern is everywhere ...\n",
    "agent.env_creator # environment is not stored, a function that creates an environment is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimeLimit<CartPoleEnv<CartPole-v0>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = agent.env_creator({}) # we can sometimes still get what we want ..\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\n",
      "Discrete(2)\n",
      "[ 4.5951862e+00 -2.4160767e+38  2.9495916e-01  5.0103560e+37]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute some observation, then ask the agent to compute an action\n",
    "obs = env.observation_space.sample()\n",
    "agent.compute_action(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE:\n",
    "Train the agent and try to get a reward of 200. If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger sgd_minibatch_size, a smaller num_sgd_iter, or a larger num_workers.\n",
    "\n",
    "This should take around 20 or 30 training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-02-19 06:16:31,647\tWARNING util.py:41 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# build out a new config and trainer\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0\n",
    "\n",
    "agent = PPOTrainer(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-41\n",
      "done: false\n",
      "episode_len_mean: 21.688524590163933\n",
      "episode_reward_max: 64.0\n",
      "episode_reward_mean: 21.688524590163933\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 183\n",
      "episodes_total: 183\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1436.923\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6632076501846313\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.029982194304466248\n",
      "      policy_loss: -0.037228453904390335\n",
      "      total_loss: 146.48733520507812\n",
      "      vf_explained_var: 0.03170539438724518\n",
      "      vf_loss: 146.51858520507812\n",
      "  load_time_ms: 49.808\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 3968\n",
      "  sample_time_ms: 1118.474\n",
      "  update_time_ms: 420.931\n",
      "iterations_since_restore: 1\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 21.69285714285714\n",
      "  ram_util_percent: 58.09999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.0536999818497411\n",
      "  mean_inference_ms: 0.5735193906863028\n",
      "  mean_processing_ms: 0.14010609805713925\n",
      "time_since_restore: 3.064250946044922\n",
      "time_this_iter_s: 3.064250946044922\n",
      "time_total_s: 3.064250946044922\n",
      "timestamp: 1582111001\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-43\n",
      "done: false\n",
      "episode_len_mean: 41.13\n",
      "episode_reward_max: 142.0\n",
      "episode_reward_mean: 41.13\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 93\n",
      "episodes_total: 276\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1334.635\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6187185645103455\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.015833476558327675\n",
      "      policy_loss: -0.02533409371972084\n",
      "      total_loss: 288.35089111328125\n",
      "      vf_explained_var: 0.03842959180474281\n",
      "      vf_loss: 288.3714904785156\n",
      "  load_time_ms: 25.474\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 7936\n",
      "  sample_time_ms: 1118.861\n",
      "  update_time_ms: 211.872\n",
      "iterations_since_restore: 2\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.925\n",
      "  ram_util_percent: 57.8\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.054443523037982604\n",
      "  mean_inference_ms: 0.5879857090135056\n",
      "  mean_processing_ms: 0.1369467934328536\n",
      "time_since_restore: 5.4237380027771\n",
      "time_this_iter_s: 2.3594870567321777\n",
      "time_total_s: 5.4237380027771\n",
      "timestamp: 1582111003\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-45\n",
      "done: false\n",
      "episode_len_mean: 64.15\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 64.15\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 42\n",
      "episodes_total: 318\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1276.428\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5829330086708069\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.010297209024429321\n",
      "      policy_loss: -0.015498858876526356\n",
      "      total_loss: 537.703857421875\n",
      "      vf_explained_var: 0.0463348813354969\n",
      "      vf_loss: 537.71630859375\n",
      "  load_time_ms: 17.331\n",
      "  num_steps_sampled: 12000\n",
      "  num_steps_trained: 11904\n",
      "  sample_time_ms: 1090.642\n",
      "  update_time_ms: 142.152\n",
      "iterations_since_restore: 3\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.4\n",
      "  ram_util_percent: 57.833333333333336\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05484678759101823\n",
      "  mean_inference_ms: 0.5860548816886189\n",
      "  mean_processing_ms: 0.13480174793705663\n",
      "time_since_restore: 7.625644683837891\n",
      "time_this_iter_s: 2.201906681060791\n",
      "time_total_s: 7.625644683837891\n",
      "timestamp: 1582111005\n",
      "timesteps_since_restore: 12000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 12000\n",
      "training_iteration: 3\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-48\n",
      "done: false\n",
      "episode_len_mean: 90.44\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 90.44\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 27\n",
      "episodes_total: 345\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1250.793\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5673893094062805\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.00588633818551898\n",
      "      policy_loss: -0.01095875259488821\n",
      "      total_loss: 877.1500244140625\n",
      "      vf_explained_var: 0.05050592124462128\n",
      "      vf_loss: 877.1590576171875\n",
      "  load_time_ms: 13.311\n",
      "  num_steps_sampled: 16000\n",
      "  num_steps_trained: 15872\n",
      "  sample_time_ms: 1075.048\n",
      "  update_time_ms: 107.291\n",
      "iterations_since_restore: 4\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.96666666666667\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05468740033693036\n",
      "  mean_inference_ms: 0.5790186214278651\n",
      "  mean_processing_ms: 0.13321518104632227\n",
      "time_since_restore: 9.835608005523682\n",
      "time_this_iter_s: 2.209963321685791\n",
      "time_total_s: 9.835608005523682\n",
      "timestamp: 1582111008\n",
      "timesteps_since_restore: 16000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 16000\n",
      "training_iteration: 4\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-50\n",
      "done: false\n",
      "episode_len_mean: 119.08\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 119.08\n",
      "episode_reward_min: 18.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 369\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1233.837\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5393790602684021\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0040593440644443035\n",
      "      policy_loss: -0.005543500185012817\n",
      "      total_loss: 753.5761108398438\n",
      "      vf_explained_var: 0.07071428745985031\n",
      "      vf_loss: 753.5802612304688\n",
      "  load_time_ms: 10.897\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 19840\n",
      "  sample_time_ms: 1069.877\n",
      "  update_time_ms: 86.467\n",
      "iterations_since_restore: 5\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.0\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05466186548781654\n",
      "  mean_inference_ms: 0.573873007068377\n",
      "  mean_processing_ms: 0.13088678492285655\n",
      "time_since_restore: 12.059091091156006\n",
      "time_this_iter_s: 2.223483085632324\n",
      "time_total_s: 12.059091091156006\n",
      "timestamp: 1582111010\n",
      "timesteps_since_restore: 20000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 20000\n",
      "training_iteration: 5\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-52\n",
      "done: false\n",
      "episode_len_mean: 144.96\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 144.96\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 392\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1219.908\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.15000000596046448\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5491452217102051\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006828633137047291\n",
      "      policy_loss: -0.002894205739721656\n",
      "      total_loss: 924.4174194335938\n",
      "      vf_explained_var: 0.16107870638370514\n",
      "      vf_loss: 924.4191284179688\n",
      "  load_time_ms: 9.262\n",
      "  num_steps_sampled: 24000\n",
      "  num_steps_trained: 23808\n",
      "  sample_time_ms: 1073.861\n",
      "  update_time_ms: 72.564\n",
      "iterations_since_restore: 6\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.93333333333334\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05498434717243351\n",
      "  mean_inference_ms: 0.5731463023254939\n",
      "  mean_processing_ms: 0.12962698449246798\n",
      "time_since_restore: 14.31097412109375\n",
      "time_this_iter_s: 2.251883029937744\n",
      "time_total_s: 14.31097412109375\n",
      "timestamp: 1582111012\n",
      "timesteps_since_restore: 24000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 24000\n",
      "training_iteration: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-54\n",
      "done: false\n",
      "episode_len_mean: 167.13\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 167.13\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 412\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1212.04\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.15000000596046448\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5691795349121094\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0049133202992379665\n",
      "      policy_loss: -0.004781582858413458\n",
      "      total_loss: 551.9776000976562\n",
      "      vf_explained_var: 0.07918348908424377\n",
      "      vf_loss: 551.9816284179688\n",
      "  load_time_ms: 8.095\n",
      "  num_steps_sampled: 28000\n",
      "  num_steps_trained: 27776\n",
      "  sample_time_ms: 1065.053\n",
      "  update_time_ms: 62.58\n",
      "iterations_since_restore: 7\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.375\n",
      "  ram_util_percent: 57.8\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05498610653852687\n",
      "  mean_inference_ms: 0.5704809923306642\n",
      "  mean_processing_ms: 0.12890540139057755\n",
      "time_since_restore: 16.495670318603516\n",
      "time_this_iter_s: 2.1846961975097656\n",
      "time_total_s: 16.495670318603516\n",
      "timestamp: 1582111014\n",
      "timesteps_since_restore: 28000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 28000\n",
      "training_iteration: 7\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-57\n",
      "done: false\n",
      "episode_len_mean: 178.05\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 178.05\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 432\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1207.624\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5343212485313416\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005321964621543884\n",
      "      policy_loss: -0.0032536888029426336\n",
      "      total_loss: 408.8269348144531\n",
      "      vf_explained_var: 0.23268884420394897\n",
      "      vf_loss: 408.8298034667969\n",
      "  load_time_ms: 7.219\n",
      "  num_steps_sampled: 32000\n",
      "  num_steps_trained: 31744\n",
      "  sample_time_ms: 1059.88\n",
      "  update_time_ms: 55.141\n",
      "iterations_since_restore: 8\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.766666666666666\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05505659185805886\n",
      "  mean_inference_ms: 0.5689376131066969\n",
      "  mean_processing_ms: 0.12812253596118256\n",
      "time_since_restore: 18.70401358604431\n",
      "time_this_iter_s: 2.208343267440796\n",
      "time_total_s: 18.70401358604431\n",
      "timestamp: 1582111017\n",
      "timesteps_since_restore: 32000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 32000\n",
      "training_iteration: 8\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-16-59\n",
      "done: false\n",
      "episode_len_mean: 185.37\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.37\n",
      "episode_reward_min: 53.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 454\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1202.573\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.505181074142456\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005868067499250174\n",
      "      policy_loss: -0.003376477863639593\n",
      "      total_loss: 458.131103515625\n",
      "      vf_explained_var: 0.4811188578605652\n",
      "      vf_loss: 458.134033203125\n",
      "  load_time_ms: 6.544\n",
      "  num_steps_sampled: 36000\n",
      "  num_steps_trained: 35712\n",
      "  sample_time_ms: 1053.228\n",
      "  update_time_ms: 49.319\n",
      "iterations_since_restore: 9\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.699999999999996\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05509781936622346\n",
      "  mean_inference_ms: 0.567423403519172\n",
      "  mean_processing_ms: 0.1273395428945979\n",
      "time_since_restore: 20.87402033805847\n",
      "time_this_iter_s: 2.17000675201416\n",
      "time_total_s: 20.87402033805847\n",
      "timestamp: 1582111019\n",
      "timesteps_since_restore: 36000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 36000\n",
      "training_iteration: 9\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-01\n",
      "done: false\n",
      "episode_len_mean: 191.16\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.16\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 474\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1195.262\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4930128753185272\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006275207735598087\n",
      "      policy_loss: -0.0026502073742449284\n",
      "      total_loss: 435.3016357421875\n",
      "      vf_explained_var: 0.42831072211265564\n",
      "      vf_loss: 435.3038330078125\n",
      "  load_time_ms: 5.997\n",
      "  num_steps_sampled: 40000\n",
      "  num_steps_trained: 39680\n",
      "  sample_time_ms: 1047.567\n",
      "  update_time_ms: 44.659\n",
      "iterations_since_restore: 10\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.699999999999996\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.055027189627899195\n",
      "  mean_inference_ms: 0.5652180993802731\n",
      "  mean_processing_ms: 0.12674144065173115\n",
      "time_since_restore: 23.007566452026367\n",
      "time_this_iter_s: 2.1335461139678955\n",
      "time_total_s: 23.007566452026367\n",
      "timestamp: 1582111021\n",
      "timesteps_since_restore: 40000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 40000\n",
      "training_iteration: 10\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-03\n",
      "done: false\n",
      "episode_len_mean: 193.11\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.11\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 494\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1165.097\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49908292293548584\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0054861088283360004\n",
      "      policy_loss: -0.0049097673036158085\n",
      "      total_loss: 466.0050048828125\n",
      "      vf_explained_var: 0.34451574087142944\n",
      "      vf_loss: 466.009521484375\n",
      "  load_time_ms: 1.132\n",
      "  num_steps_sampled: 44000\n",
      "  num_steps_trained: 43648\n",
      "  sample_time_ms: 1037.242\n",
      "  update_time_ms: 2.83\n",
      "iterations_since_restore: 11\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.13333333333333\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05487274058725171\n",
      "  mean_inference_ms: 0.5623453945014538\n",
      "  mean_processing_ms: 0.12599241620416207\n",
      "time_since_restore: 25.1657075881958\n",
      "time_this_iter_s: 2.1581411361694336\n",
      "time_total_s: 25.1657075881958\n",
      "timestamp: 1582111023\n",
      "timesteps_since_restore: 44000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 44000\n",
      "training_iteration: 11\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-05\n",
      "done: false\n",
      "episode_len_mean: 193.64\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.64\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 514\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1155.623\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.504181981086731\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005549073219299316\n",
      "      policy_loss: -0.001932564307935536\n",
      "      total_loss: 427.5368957519531\n",
      "      vf_explained_var: 0.3321417272090912\n",
      "      vf_loss: 427.5384216308594\n",
      "  load_time_ms: 1.132\n",
      "  num_steps_sampled: 48000\n",
      "  num_steps_trained: 47616\n",
      "  sample_time_ms: 1025.955\n",
      "  update_time_ms: 2.79\n",
      "iterations_since_restore: 12\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.46666666666667\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.054736520728523884\n",
      "  mean_inference_ms: 0.5600240503238934\n",
      "  mean_processing_ms: 0.12533995762664174\n",
      "time_since_restore: 27.317099571228027\n",
      "time_this_iter_s: 2.1513919830322266\n",
      "time_total_s: 27.317099571228027\n",
      "timestamp: 1582111025\n",
      "timesteps_since_restore: 48000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 48000\n",
      "training_iteration: 12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-07\n",
      "done: false\n",
      "episode_len_mean: 195.61\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.61\n",
      "episode_reward_min: 141.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 534\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1157.439\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48373815417289734\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005612557753920555\n",
      "      policy_loss: -0.0031816435512155294\n",
      "      total_loss: 348.22845458984375\n",
      "      vf_explained_var: 0.44983890652656555\n",
      "      vf_loss: 348.231201171875\n",
      "  load_time_ms: 1.139\n",
      "  num_steps_sampled: 52000\n",
      "  num_steps_trained: 51584\n",
      "  sample_time_ms: 1023.266\n",
      "  update_time_ms: 2.823\n",
      "iterations_since_restore: 13\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.5\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.054608570750983\n",
      "  mean_inference_ms: 0.5580513166026086\n",
      "  mean_processing_ms: 0.12471375330739227\n",
      "time_since_restore: 29.510529279708862\n",
      "time_this_iter_s: 2.193429708480835\n",
      "time_total_s: 29.510529279708862\n",
      "timestamp: 1582111027\n",
      "timesteps_since_restore: 52000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 52000\n",
      "training_iteration: 13\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-10\n",
      "done: false\n",
      "episode_len_mean: 199.41\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.41\n",
      "episode_reward_min: 162.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 554\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1153.867\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5030777454376221\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0053413002751767635\n",
      "      policy_loss: -0.0022586281411349773\n",
      "      total_loss: 255.88807678222656\n",
      "      vf_explained_var: 0.584119975566864\n",
      "      vf_loss: 255.8899383544922\n",
      "  load_time_ms: 1.129\n",
      "  num_steps_sampled: 56000\n",
      "  num_steps_trained: 55552\n",
      "  sample_time_ms: 1018.686\n",
      "  update_time_ms: 2.812\n",
      "iterations_since_restore: 14\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.833333333333336\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05447209156401461\n",
      "  mean_inference_ms: 0.5561294528850143\n",
      "  mean_processing_ms: 0.12411543711937073\n",
      "time_since_restore: 31.63873052597046\n",
      "time_this_iter_s: 2.1282012462615967\n",
      "time_total_s: 31.63873052597046\n",
      "timestamp: 1582111030\n",
      "timesteps_since_restore: 56000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 56000\n",
      "training_iteration: 14\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-12\n",
      "done: false\n",
      "episode_len_mean: 199.86\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.86\n",
      "episode_reward_min: 190.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 574\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1156.89\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49292972683906555\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.004661330487579107\n",
      "      policy_loss: -0.0030282619409263134\n",
      "      total_loss: 317.4492492675781\n",
      "      vf_explained_var: 0.49302607774734497\n",
      "      vf_loss: 317.4519348144531\n",
      "  load_time_ms: 1.116\n",
      "  num_steps_sampled: 60000\n",
      "  num_steps_trained: 59520\n",
      "  sample_time_ms: 1013.416\n",
      "  update_time_ms: 2.763\n",
      "iterations_since_restore: 15\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.800000000000004\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05437850989678437\n",
      "  mean_inference_ms: 0.5546976885648618\n",
      "  mean_processing_ms: 0.12365538354068079\n",
      "time_since_restore: 33.839282274246216\n",
      "time_this_iter_s: 2.200551748275757\n",
      "time_total_s: 33.839282274246216\n",
      "timestamp: 1582111032\n",
      "timesteps_since_restore: 60000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 60000\n",
      "training_iteration: 15\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-14\n",
      "done: false\n",
      "episode_len_mean: 199.86\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.86\n",
      "episode_reward_min: 190.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 594\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1161.634\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48536133766174316\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006934709381312132\n",
      "      policy_loss: -0.007096285466104746\n",
      "      total_loss: 376.55206298828125\n",
      "      vf_explained_var: 0.40169182419776917\n",
      "      vf_loss: 376.5588684082031\n",
      "  load_time_ms: 1.113\n",
      "  num_steps_sampled: 64000\n",
      "  num_steps_trained: 63488\n",
      "  sample_time_ms: 1007.652\n",
      "  update_time_ms: 2.719\n",
      "iterations_since_restore: 16\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.325\n",
      "  ram_util_percent: 57.8\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05428820787429674\n",
      "  mean_inference_ms: 0.5534963077335926\n",
      "  mean_processing_ms: 0.12328368649019118\n",
      "time_since_restore: 36.08069372177124\n",
      "time_this_iter_s: 2.2414114475250244\n",
      "time_total_s: 36.08069372177124\n",
      "timestamp: 1582111034\n",
      "timesteps_since_restore: 64000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 64000\n",
      "training_iteration: 16\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-16\n",
      "done: false\n",
      "episode_len_mean: 199.86\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.86\n",
      "episode_reward_min: 190.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 614\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1164.288\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48617997765541077\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.007853729650378227\n",
      "      policy_loss: -0.002457919530570507\n",
      "      total_loss: 463.0928955078125\n",
      "      vf_explained_var: 0.3113935589790344\n",
      "      vf_loss: 463.0950927734375\n",
      "  load_time_ms: 1.127\n",
      "  num_steps_sampled: 68000\n",
      "  num_steps_trained: 67456\n",
      "  sample_time_ms: 1011.495\n",
      "  update_time_ms: 2.766\n",
      "iterations_since_restore: 17\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.96666666666667\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05425648821982623\n",
      "  mean_inference_ms: 0.5528792072367986\n",
      "  mean_processing_ms: 0.12299207127378115\n",
      "time_since_restore: 38.33085298538208\n",
      "time_this_iter_s: 2.25015926361084\n",
      "time_total_s: 38.33085298538208\n",
      "timestamp: 1582111036\n",
      "timesteps_since_restore: 68000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 68000\n",
      "training_iteration: 17\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-18\n",
      "done: false\n",
      "episode_len_mean: 199.86\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.86\n",
      "episode_reward_min: 190.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 634\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1161.582\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49710723757743835\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0021759015507996082\n",
      "      policy_loss: -0.0015563026536256075\n",
      "      total_loss: 576.7896118164062\n",
      "      vf_explained_var: 0.1895386129617691\n",
      "      vf_loss: 576.7911376953125\n",
      "  load_time_ms: 1.13\n",
      "  num_steps_sampled: 72000\n",
      "  num_steps_trained: 71424\n",
      "  sample_time_ms: 1014.26\n",
      "  update_time_ms: 2.845\n",
      "iterations_since_restore: 18\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.6\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05426220469825493\n",
      "  mean_inference_ms: 0.5525600694239688\n",
      "  mean_processing_ms: 0.12286054568863751\n",
      "time_since_restore: 40.54060363769531\n",
      "time_this_iter_s: 2.2097506523132324\n",
      "time_total_s: 40.54060363769531\n",
      "timestamp: 1582111038\n",
      "timesteps_since_restore: 72000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 72000\n",
      "training_iteration: 18\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-21\n",
      "done: false\n",
      "episode_len_mean: 199.86\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.86\n",
      "episode_reward_min: 190.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 654\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1162.005\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.01875000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4989548623561859\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0031236193608492613\n",
      "      policy_loss: -0.0016235418152064085\n",
      "      total_loss: 554.27783203125\n",
      "      vf_explained_var: 0.2152165174484253\n",
      "      vf_loss: 554.2794799804688\n",
      "  load_time_ms: 1.14\n",
      "  num_steps_sampled: 76000\n",
      "  num_steps_trained: 75392\n",
      "  sample_time_ms: 1021.2\n",
      "  update_time_ms: 2.889\n",
      "iterations_since_restore: 19\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.76666666666667\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05431479345145876\n",
      "  mean_inference_ms: 0.5528248494506149\n",
      "  mean_processing_ms: 0.12282590153835717\n",
      "time_since_restore: 42.78471779823303\n",
      "time_this_iter_s: 2.2441141605377197\n",
      "time_total_s: 42.78471779823303\n",
      "timestamp: 1582111041\n",
      "timesteps_since_restore: 76000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 76000\n",
      "training_iteration: 19\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-19_06-17-23\n",
      "done: false\n",
      "episode_len_mean: 199.84\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.84\n",
      "episode_reward_min: 184.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 674\n",
      "experiment_id: 56ddc8b53d0a4cc99a9162ca02685189\n",
      "hostname: GDA-Oryx-Pro\n",
      "info:\n",
      "  grad_time_ms: 1162.485\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47821322083473206\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.004409750457853079\n",
      "      policy_loss: -0.0036050984635949135\n",
      "      total_loss: 525.3309936523438\n",
      "      vf_explained_var: 0.23890428245067596\n",
      "      vf_loss: 525.3345336914062\n",
      "  load_time_ms: 1.138\n",
      "  num_steps_sampled: 80000\n",
      "  num_steps_trained: 79360\n",
      "  sample_time_ms: 1022.649\n",
      "  update_time_ms: 2.868\n",
      "iterations_since_restore: 20\n",
      "node_ip: 192.168.1.170\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.333333333333336\n",
      "  ram_util_percent: 57.79999999999999\n",
      "pid: 19949\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.05437580810643601\n",
      "  mean_inference_ms: 0.5531976478641321\n",
      "  mean_processing_ms: 0.12278650439225912\n",
      "time_since_restore: 44.93761491775513\n",
      "time_this_iter_s: 2.1528971195220947\n",
      "time_total_s: 44.93761491775513\n",
      "timestamp: 1582111043\n",
      "timesteps_since_restore: 80000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 80000\n",
      "training_iteration: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train for a while\n",
    "for i in range(20):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhineman/ray_results/PPO_CartPole-v0_2020-02-19_06-16-28270n8w37/checkpoint_20/checkpoint-20\n"
     ]
    }
   ],
   "source": [
    "## Save the agent off (this may become sticky depending which agent you've used)\n",
    "checkpoint_path = agent.save()\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-02-19 06:23:08,091\tWARNING worker.py:1063 -- WARNING: 9 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2020-02-19 06:23:09,870\tWARNING util.py:41 -- Install gputil for GPU system monitoring.\n",
      "2020-02-19 06:23:09,964\tWARNING trainable.py:210 -- Getting current IP.\n",
      "2020-02-19 06:23:09,965\tINFO trainable.py:416 -- Restored on 192.168.1.170 from checkpoint: /home/jhineman/ray_results/PPO_CartPole-v0_2020-02-19_06-16-28270n8w37/checkpoint_20/checkpoint-20\n",
      "2020-02-19 06:23:09,965\tINFO trainable.py:423 -- Current state after restoring: {'_iteration': 20, '_timesteps_total': 80000, '_time_total': 44.93761491775513, '_episodes_total': 674}\n"
     ]
    }
   ],
   "source": [
    "trained_config = config.copy() # copy training config (this is also located in ~/ray_results)\n",
    "test_agent = PPOTrainer(trained_config, 'CartPole-v0')\n",
    "test_agent.restore(checkpoint_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE:\n",
    "Verify that the reward received roughly matches up with the reward printed in the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "# same a single trajectory\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow ups:\n",
    "1. Using the `test_agent` what is the distribution of cummulative reward?\n",
    "1. Instead of a well trained agent, what does a poorly trained agent reward distribution look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring tune\n",
    "https://ray.readthedocs.io/en/latest/tune-usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Get logging from previous ppo training into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: setuptools in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# matplotlib and magic\n",
    "! pip install matplotlib\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import Analysis\n",
    "# change paths appropriately\n",
    "analysis = Analysis(\"/home/jhineman/ray_results/PPO_CartPole-v0_2020-02-19_06-16-28270n8w37\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe() # last trial from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = analysis.trial_dataframes['/home/jhineman/ray_results/PPO_CartPole-v0_2020-02-19_06-16-28270n8w37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f546549dd10>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials['episode_reward_mean'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Look at same with tensorboard. In a console, start tensorboard with: `tensorboard --logdir=~/ray_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.27.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (3.11.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (45.2.0.post20200210)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=~/ray_results # Kernel -> interupt to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details on tune\n",
    "* https://github.com/ray-project/ray/tree/master/rllib/tuned_examples list essentially yaml that can be used with the command line interface for tune\n",
    "* we will use tune to run of the a3c examples (this is a cpu only regression test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /home/jhineman/.conda/envs/ray_ece/lib/python3.7/site-packages (5.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pyyaml # install package to read yamls, import with yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'# This gets to ~19-20 reward in ~30 minutes / 4m steps on a m4.10xl instance\\n# TODO(rliaw): this has regressed in performance\\npong-a3c:\\n    env: PongDeterministic-v4\\n    run: A3C\\n    config:\\n        num_workers: 16\\n        sample_batch_size: 20\\n        use_pytorch: false\\n        vf_loss_coeff: 0.5\\n        entropy_coeff: 0.01\\n        gamma: 0.99\\n        grad_clip: 40.0\\n        lambda: 1.0\\n        lr: 0.0001\\n        observation_filter: NoFilter\\n        preprocessor_pref: rllib\\n        model:\\n            use_lstm: true\\n            conv_activation: elu\\n            dim: 42\\n            grayscale: true\\n            zero_mean: false\\n            # Reduced channel depth and kernel size from default\\n            conv_filters: [\\n                [32, [3, 3], 2],\\n                [32, [3, 3], 2],\\n                [32, [3, 3], 2],\\n                [32, [3, 3], 2],\\n            ]\\n'\n"
     ]
    }
   ],
   "source": [
    "# grab an a3c example from github\n",
    "link = \"https://raw.githubusercontent.com/ray-project/ray/master/rllib/tuned_examples/pong-a3c.yaml\"\n",
    "f = urllib.request.urlopen(link)\n",
    "yaml_example = f.read()\n",
    "print(yaml_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pong-a3c': {'env': 'PongDeterministic-v4', 'run': 'A3C', 'config': {'num_workers': 16, 'sample_batch_size': 20, 'use_pytorch': False, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'gamma': 0.99, 'grad_clip': 40.0, 'lambda': 1.0, 'lr': 0.0001, 'observation_filter': 'NoFilter', 'preprocessor_pref': 'rllib', 'model': {'use_lstm': True, 'conv_activation': 'elu', 'dim': 42, 'grayscale': True, 'zero_mean': False, 'conv_filters': [[32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2]]}}}}\n"
     ]
    }
   ],
   "source": [
    "tune_config_example = yaml.safe_load(yaml_example)\n",
    "print(tune_config_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pong-a3c': {'run': 'A3C', 'config': {'num_workers': 2, 'sample_batch_size': 20, 'use_pytorch': False, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'gamma': 0.99, 'grad_clip': 40.0, 'lambda': 1.0, 'lr': 0.0001, 'observation_filter': 'NoFilter', 'preprocessor_pref': 'rllib', 'model': {'use_lstm': True, 'conv_activation': 'elu', 'dim': 42, 'grayscale': True, 'zero_mean': False, 'conv_filters': [[32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2], [32, [3, 3], 2]]}, 'env': 'PongDeterministic-v4'}, 'stop': {'training_iteration': 10}}}\n"
     ]
    }
   ],
   "source": [
    "tune_config_example[\"pong-a3c\"][\"config\"][\"num_workers\"]=2\n",
    "tune_config_example[\"pong-a3c\"][\"stop\"] = {\"training_iteration\": 10}\n",
    "print(tune_config_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 07:35:22,952\tWARNING worker.py:1063 -- WARNING: 10 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2020-02-19 07:35:22,953\tWARNING worker.py:1063 -- WARNING: 11 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-35-30\n",
      "  done: false\n",
      "  episode_len_mean: 933.0\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -19.0\n",
      "  episode_reward_min: -19.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.999\n",
      "    dispatch_time_ms: 6.055\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 6.20143985748291\n",
      "      model: {}\n",
      "      policy_entropy: 35.828086853027344\n",
      "      policy_loss: 4.84628963470459\n",
      "      var_gnorm: 25.89760398864746\n",
      "      vf_explained_var: -0.14878058433532715\n",
      "      vf_loss: 0.20017409324645996\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    wait_time_ms: 28.359\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.48333333333333\n",
      "    ram_util_percent: 72.73333333333333\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.064345254226224\n",
      "    mean_inference_ms: 2.398835554759871\n",
      "    mean_processing_ms: 0.5544763252698055\n",
      "  time_since_restore: 7.688481092453003\n",
      "  time_this_iter_s: 7.688481092453003\n",
      "  time_total_s: 7.688481092453003\n",
      "  timestamp: 1582115730\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 2000\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 1\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.68848</td><td style=\"text-align: right;\">       2000</td><td style=\"text-align: right;\">     -19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-35-38\n",
      "  done: false\n",
      "  episode_len_mean: 923.8\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 5\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.702\n",
      "    dispatch_time_ms: 6.428\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 8.23530101776123\n",
      "      model: {}\n",
      "      policy_entropy: 35.81895446777344\n",
      "      policy_loss: -7.796582221984863\n",
      "      var_gnorm: 25.91107177734375\n",
      "      vf_explained_var: -0.03810453414916992\n",
      "      vf_loss: 2.049349546432495\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 6000\n",
      "    wait_time_ms: 29.956\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.36363636363635\n",
      "    ram_util_percent: 77.70000000000002\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0870691430137014\n",
      "    mean_inference_ms: 2.3113818489198876\n",
      "    mean_processing_ms: 0.5591501314287768\n",
      "  time_since_restore: 15.394580125808716\n",
      "  time_this_iter_s: 7.706099033355713\n",
      "  time_total_s: 15.394580125808716\n",
      "  timestamp: 1582115738\n",
      "  timesteps_since_restore: 6000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 2\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         15.3946</td><td style=\"text-align: right;\">       6000</td><td style=\"text-align: right;\">     -20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-35-46\n",
      "  done: false\n",
      "  episode_len_mean: 961.3\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.3\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.92\n",
      "    dispatch_time_ms: 5.979\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 25.66436004638672\n",
      "      model: {}\n",
      "      policy_entropy: 35.73349380493164\n",
      "      policy_loss: -15.589995384216309\n",
      "      var_gnorm: 25.9265079498291\n",
      "      vf_explained_var: 0.009191632270812988\n",
      "      vf_loss: 3.177231788635254\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    wait_time_ms: 29.865\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.17272727272728\n",
      "    ram_util_percent: 81.27272727272727\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0907881825538652\n",
      "    mean_inference_ms: 2.269095055144653\n",
      "    mean_processing_ms: 0.5630653932173435\n",
      "  time_since_restore: 22.9931218624115\n",
      "  time_this_iter_s: 7.598541736602783\n",
      "  time_total_s: 22.9931218624115\n",
      "  timestamp: 1582115746\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 3\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         22.9931</td><td style=\"text-align: right;\">      10000</td><td style=\"text-align: right;\">   -20.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-35-53\n",
      "  done: false\n",
      "  episode_len_mean: 925.1428571428571\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.428571428571427\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 14\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.613\n",
      "    dispatch_time_ms: 6.634\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 10.969645500183105\n",
      "      model: {}\n",
      "      policy_entropy: 35.18730163574219\n",
      "      policy_loss: -5.459041118621826\n",
      "      var_gnorm: 25.94123077392578\n",
      "      vf_explained_var: -0.00879526138305664\n",
      "      vf_loss: 1.4715474843978882\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 14000\n",
      "    wait_time_ms: 27.919\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.02\n",
      "    ram_util_percent: 84.48\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0918355972828286\n",
      "    mean_inference_ms: 2.2453217256831763\n",
      "    mean_processing_ms: 0.5642070539908823\n",
      "  time_since_restore: 30.519699573516846\n",
      "  time_this_iter_s: 7.526577711105347\n",
      "  time_total_s: 30.519699573516846\n",
      "  timestamp: 1582115753\n",
      "  timesteps_since_restore: 14000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 4\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         30.5197</td><td style=\"text-align: right;\">      14000</td><td style=\"text-align: right;\">-20.4286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-36-01\n",
      "  done: false\n",
      "  episode_len_mean: 879.6\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.6\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 20\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.874\n",
      "    dispatch_time_ms: 5.737\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 6.833588123321533\n",
      "      model: {}\n",
      "      policy_entropy: 35.36431121826172\n",
      "      policy_loss: -1.3010973930358887\n",
      "      var_gnorm: 25.95338249206543\n",
      "      vf_explained_var: 0.010339975357055664\n",
      "      vf_loss: 1.2181718349456787\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 18000\n",
      "    wait_time_ms: 28.391\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.93636363636363\n",
      "    ram_util_percent: 87.5909090909091\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0921311143736134\n",
      "    mean_inference_ms: 2.2176966235863027\n",
      "    mean_processing_ms: 0.5654628336884177\n",
      "  time_since_restore: 37.91316270828247\n",
      "  time_this_iter_s: 7.393463134765625\n",
      "  time_total_s: 37.91316270828247\n",
      "  timestamp: 1582115761\n",
      "  timesteps_since_restore: 18000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 5\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         37.9132</td><td style=\"text-align: right;\">      18000</td><td style=\"text-align: right;\">   -20.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-36-08\n",
      "  done: false\n",
      "  episode_len_mean: 866.5\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.666666666666668\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 24\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.551\n",
      "    dispatch_time_ms: 5.731\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 27.192237854003906\n",
      "      model: {}\n",
      "      policy_entropy: 34.851470947265625\n",
      "      policy_loss: -17.285873413085938\n",
      "      var_gnorm: 25.980113983154297\n",
      "      vf_explained_var: 0.0008727908134460449\n",
      "      vf_loss: 3.459970474243164\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 22000\n",
      "    wait_time_ms: 29.62\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.48181818181818\n",
      "    ram_util_percent: 90.74545454545454\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0921053681101105\n",
      "    mean_inference_ms: 2.20449387003933\n",
      "    mean_processing_ms: 0.5657095941701771\n",
      "  time_since_restore: 45.36849808692932\n",
      "  time_this_iter_s: 7.455335378646851\n",
      "  time_total_s: 45.36849808692932\n",
      "  timestamp: 1582115768\n",
      "  timesteps_since_restore: 22000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 6\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         45.3685</td><td style=\"text-align: right;\">      22000</td><td style=\"text-align: right;\">-20.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-36-15\n",
      "  done: false\n",
      "  episode_len_mean: 852.6666666666666\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.733333333333334\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 30\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 2.217\n",
      "    dispatch_time_ms: 5.555\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 34.026512145996094\n",
      "      model: {}\n",
      "      policy_entropy: 35.20148849487305\n",
      "      policy_loss: -24.611927032470703\n",
      "      var_gnorm: 26.00190544128418\n",
      "      vf_explained_var: -0.06230795383453369\n",
      "      vf_loss: 5.48494291305542\n",
      "    num_steps_sampled: 26000\n",
      "    num_steps_trained: 26000\n",
      "    wait_time_ms: 29.047\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.980000000000004\n",
      "    ram_util_percent: 92.82\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.091587150686514\n",
      "    mean_inference_ms: 2.188483048308026\n",
      "    mean_processing_ms: 0.5660231257457201\n",
      "  time_since_restore: 52.748388051986694\n",
      "  time_this_iter_s: 7.379889965057373\n",
      "  time_total_s: 52.748388051986694\n",
      "  timestamp: 1582115775\n",
      "  timesteps_since_restore: 26000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 26000\n",
      "  training_iteration: 7\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         52.7484</td><td style=\"text-align: right;\">      26000</td><td style=\"text-align: right;\">-20.7333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 865.1176470588235\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.705882352941178\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 34\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.56\n",
      "    dispatch_time_ms: 5.832\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 3.5779833793640137\n",
      "      model: {}\n",
      "      policy_entropy: 35.12071228027344\n",
      "      policy_loss: -0.23137566447257996\n",
      "      var_gnorm: 26.018766403198242\n",
      "      vf_explained_var: -0.0048400163650512695\n",
      "      vf_loss: 1.1878029108047485\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    wait_time_ms: 29.938\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.27272727272726\n",
      "    ram_util_percent: 93.39090909090909\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0910899229817492\n",
      "    mean_inference_ms: 2.1793531264500405\n",
      "    mean_processing_ms: 0.5659853988455774\n",
      "  time_since_restore: 60.075438022613525\n",
      "  time_this_iter_s: 7.327049970626831\n",
      "  time_total_s: 60.075438022613525\n",
      "  timestamp: 1582115783\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 8\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         60.0754</td><td style=\"text-align: right;\">      30000</td><td style=\"text-align: right;\">-20.7059</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-36-30\n",
      "  done: false\n",
      "  episode_len_mean: 879.2894736842105\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.657894736842106\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 38\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.737\n",
      "    dispatch_time_ms: 5.849\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 33.95669174194336\n",
      "      model: {}\n",
      "      policy_entropy: 35.040000915527344\n",
      "      policy_loss: -25.83295440673828\n",
      "      var_gnorm: 26.031211853027344\n",
      "      vf_explained_var: 0.0006200671195983887\n",
      "      vf_loss: 5.436253547668457\n",
      "    num_steps_sampled: 34000\n",
      "    num_steps_trained: 34000\n",
      "    wait_time_ms: 31.685\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.730000000000004\n",
      "    ram_util_percent: 93.62\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.0905932201233757\n",
      "    mean_inference_ms: 2.171491708504847\n",
      "    mean_processing_ms: 0.5658843596621465\n",
      "  time_since_restore: 67.46936345100403\n",
      "  time_this_iter_s: 7.393925428390503\n",
      "  time_total_s: 67.46936345100403\n",
      "  timestamp: 1582115790\n",
      "  timesteps_since_restore: 34000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 34000\n",
      "  training_iteration: 9\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>RUNNING </td><td>192.168.1.170:22426</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         67.4694</td><td style=\"text-align: right;\">      34000</td><td style=\"text-align: right;\">-20.6579</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for A3C_PongDeterministic-v4_4a3c1462:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-02-19_07-36-38\n",
      "  done: true\n",
      "  episode_len_mean: 880.047619047619\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.69047619047619\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 42\n",
      "  experiment_id: fb04f05f108d4f35b1b0e443d0014176\n",
      "  experiment_tag: '0'\n",
      "  hostname: GDA-Oryx-Pro\n",
      "  info:\n",
      "    apply_time_ms: 1.75\n",
      "    dispatch_time_ms: 6.067\n",
      "    learner:\n",
      "      cur_lr: 9.999999747378752e-05\n",
      "      grad_gnorm: 11.634791374206543\n",
      "      model: {}\n",
      "      policy_entropy: 34.87805938720703\n",
      "      policy_loss: 7.163380146026611\n",
      "      var_gnorm: 26.045175552368164\n",
      "      vf_explained_var: -0.0026030540466308594\n",
      "      vf_loss: 0.5883638858795166\n",
      "    num_steps_sampled: 38000\n",
      "    num_steps_trained: 38000\n",
      "    wait_time_ms: 28.973\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.170\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.0090909090909\n",
      "    ram_util_percent: 94.2272727272727\n",
      "  pid: 22426\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.090141001210105\n",
      "    mean_inference_ms: 2.164392853752757\n",
      "    mean_processing_ms: 0.565782343205194\n",
      "  time_since_restore: 74.80961513519287\n",
      "  time_this_iter_s: 7.340251684188843\n",
      "  time_total_s: 74.80961513519287\n",
      "  timestamp: 1582115798\n",
      "  timesteps_since_restore: 38000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 38000\n",
      "  training_iteration: 10\n",
      "  trial_id: 4a3c1462\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         74.8096</td><td style=\"text-align: right;\">      38000</td><td style=\"text-align: right;\">-20.6905</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/3 CPUs, 0/1 GPUs, 0.0/4.88 GiB heap, 0.0/1.66 GiB objects<br>Result logdir: /home/jhineman/ray_results/pong-a3c<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  timesteps</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>A3C_PongDeterministic-v4_4a3c1462</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         74.8096</td><td style=\"text-align: right;\">      38000</td><td style=\"text-align: right;\">-20.6905</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[A3C_PongDeterministic-v4_4a3c1462]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.tune.run_experiments(tune_config_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting status and stopping ray\n",
    "* https://ray.readthedocs.io/en/latest/package-ref.html#ray-package-reference\n",
    "* https://ray.readthedocs.io/en/latest/package-ref.html#ray.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': 'eb9b742310e4451ea650be653b435b72e90dc48a',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '192.168.1.170',\n",
       "  'NodeManagerHostname': 'GDA-Oryx-Pro',\n",
       "  'NodeManagerPort': 41117,\n",
       "  'ObjectManagerPort': 38509,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2020-02-19_05-47-35_354974_19949/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2020-02-19_05-47-35_354974_19949/sockets/raylet',\n",
       "  'Resources': {'node:192.168.1.170': 1.0,\n",
       "   'CPU': 3.0,\n",
       "   'memory': 100.0,\n",
       "   'GPU': 1.0,\n",
       "   'object_store_memory': 34.0},\n",
       "  'alive': True}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node:192.168.1.170': 1.0,\n",
       " 'CPU': 3.0,\n",
       " 'memory': 100.0,\n",
       " 'GPU': 1.0,\n",
       " 'object_store_memory': 34.0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
